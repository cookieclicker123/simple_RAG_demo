# Pydantic models for data validation and structured data handling.

from pydantic import BaseModel, Field
from typing import List, Optional
from uuid import UUID, uuid4
from pathlib import Path
from datetime import datetime, timezone

# Example Pydantic model (can be expanded later)
class DocumentMetadata(BaseModel):
    source: str = Field(description="The source identifier of the document, e.g., file path or URL")
    page_number: Optional[int] = Field(None, description="Page number if applicable")
    last_modified: Optional[str] = Field(None, description="Last modified timestamp of the document")

class Chunk(BaseModel):
    text: str = Field(description="The text content of the chunk")
    metadata: DocumentMetadata = Field(description="Metadata associated with the chunk")
    embedding: Optional[List[float]] = Field(None, description="The vector embedding of the chunk text")

class Query(BaseModel):
    question: str = Field(description="The user's query")
    chat_history: Optional[List[dict]] = Field(None, description="Previous conversation turns")

class Answer(BaseModel):
    answer: str = Field(description="The LLM generated answer")
    retrieved_contexts: Optional[List[Chunk]] = Field(None, description="List of retrieved context chunks used for the answer")
    source_documents: Optional[List[str]] = Field(None, description="List of source document identifiers relevant to the answer")

class DocumentCitation(BaseModel):
    document_id: UUID = Field(default_factory=uuid4, description="Unique identifier for the cited document chunk or reference.")
    document_name: Optional[str] = Field(None, description="Name of the document, derived from filename (e.g., 'LMS24_en').")
    document_title: Optional[str] = Field(None, description="Extracted or derived title of the document.")
    file_path: Optional[str] = Field(None, description="Relative file path to the document (e.g., 'data/LMS24_en.pdf').")
    page_label: Optional[str] = Field(None, description="Page number or label within the document where the information was found.")
    snippet: Optional[str] = Field(None, description="A short snippet of text from the document relevant to the answer (first ~200 chars).")

# New model for structured RAG response output
class RAGSourceNodeDetail(BaseModel):
    node_id: str
    file_path: Optional[str]
    page_label: Optional[str]
    score: Optional[float] = Field(None, description="Normalized relevance score (e.g., sigmoid of reranker logit), typically 0 to 1. Higher is more relevant.")
    node_title: Optional[str] # Title generated by LLM for the node/document
    full_text_content: str = Field(description="Full text content of the source node")

class RAGResponse(BaseModel):
    query_time_utc: datetime = Field(description="Timestamp when the query was received (UTC)")
    response_time_utc: datetime = Field(description="Timestamp when the response generation was completed (UTC)")
    processing_duration_seconds: float = Field(description="Total time taken from query receipt to response completion")
    original_query: str = Field(description="The original query submitted by the user")
    
    llm_model_used: str = Field(description="Identifier of the LLM used for synthesis (e.g., gpt-4o-mini)")
    embedding_model_name_config: str = Field(description="Embedding model name from configuration")
    retriever_similarity_top_k_config: int = Field(description="Configured similarity_top_k for the initial retriever")
    reranker_model_name_config: str = Field(description="Reranker model name from configuration")
    reranker_top_n_config: int = Field(description="Configured top_n for the reranker")
    
    source_nodes_count_after_reranking: int = Field(description="Number of source nodes remaining after reranking")
    source_nodes_details: List[RAGSourceNodeDetail] = Field(description="Details of the source nodes used for the response, after reranking")
    
    final_answer_text: str = Field(description="The complete text of the generated answer")
    citations_generated: List[DocumentCitation] = Field(description="List of document citations generated for the answer")
    bm25_raw_retrieved_snippets: Optional[List[str]] = Field(None, description="Snippets from top N raw BM25 results before fusion/reranking, for observability.") 
    expanded_queries: Optional[List[str]] = Field(None, description="Queries generated by the query expansion step, if any, including the original.") 